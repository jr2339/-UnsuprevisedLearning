d.mat <- stats::dist(X, method="manhattan")
as.matrix(d.mat)
cl.tree <- stats::hclust(d.mat, method="single")
stats::cutree(cl.tree, k=3)
}, kmeans={
stats::kmeans(X, 3)
})
time.dt.list[[paste(N)]] <- data.table(N, timing.df)
}
time.dt <- do.call(rbind, time.dt.list)
time.dt[, data.size := N]
time.dt[, time.seconds := time/1e9]
time.dt[, algorithm := expr]
ggplot()+geom_point(aes(x=data.size,y=time.seconds,color=algorithm),data=time.dt)
}
Myplot(df,1000)
time.dt
Myplot(df)
Myplot <- function(data.set){
time.dt.list <- list()
for (N in seq(100, 1000, by =100)) {
X <- data.set[1:N,]
timing.df <- microbenchmark::microbenchmark(hclust={
d.mat <- stats::dist(X, method="manhattan")
as.matrix(d.mat)
cl.tree <- stats::hclust(d.mat, method="single")
stats::cutree(cl.tree, k=3)
}, kmeans={
stats::kmeans(X, 3)
})
time.dt.list[[paste(N)]] <- data.table(N, timing.df)
}
time.dt <- do.call(rbind, time.dt.list)
# time.dt[, data.size := N]
# time.dt[, time.seconds := time/1e9]
# time.dt[, algorithm := expr]
# g <- ggplot() + geom_line(aes(time.dt$,MC.dt$loglik)) + xlab("the number of mixcomponents") + ylab("the log likelihood")
# ggplot()+geom_point(aes(x=data.size,y=time.seconds,color=algorithm),data=time.dt)
}
Myplot(df,1000)
Myplot <- function(data.set){
time.dt.list <- list()
for (N in seq(100, 1000, by =100)) {
X <- data.set[1:N,]
timing.df <- microbenchmark::microbenchmark(hclust={
d.mat <- stats::dist(X, method="manhattan")
as.matrix(d.mat)
cl.tree <- stats::hclust(d.mat, method="single")
stats::cutree(cl.tree, k=3)
}, kmeans={
stats::kmeans(X, 3)
})
time.dt.list[[paste(N)]] <- data.table(N, timing.df)
}
time.dt <- do.call(rbind, time.dt.list)
# time.dt[, data.size := N]
# time.dt[, time.seconds := time/1e9]
# time.dt[, algorithm := expr]
# g <- ggplot() + geom_line(aes(time.dt$,MC.dt$loglik)) + xlab("the number of mixcomponents") + ylab("the log likelihood")
# ggplot()+geom_point(aes(x=data.size,y=time.seconds,color=algorithm),data=time.dt)
}
Myplot(df)
Myplot <- function(data.set){
time.dt.list <- list()
for (N in seq(10, 50, by =10)) {
X <- data.set[1:N,]
timing.df <- microbenchmark::microbenchmark(hclust={
d.mat <- stats::dist(X, method="manhattan")
as.matrix(d.mat)
cl.tree <- stats::hclust(d.mat, method="single")
stats::cutree(cl.tree, k=3)
}, kmeans={
stats::kmeans(X, 3)
})
time.dt.list[[paste(N)]] <- data.table(N, timing.df)
}
time.dt <- do.call(rbind, time.dt.list)
# time.dt[, data.size := N]
# time.dt[, time.seconds := time/1e9]
# time.dt[, algorithm := expr]
# g <- ggplot() + geom_line(aes(time.dt$,MC.dt$loglik)) + xlab("the number of mixcomponents") + ylab("the log likelihood")
# ggplot()+geom_point(aes(x=data.size,y=time.seconds,color=algorithm),data=time.dt)
}
Myplot(df)
time.dt
Myplot(df)
time.dt
r<-Myplot(df)
r
Myplot <- function(data.set){
time.dt.list <- list()
for (N in seq(10, 50, by =10)) {
X <- data.set[1:N,]
timing.df <- microbenchmark::microbenchmark(hclust={
d.mat <- stats::dist(X, method="manhattan")
as.matrix(d.mat)
cl.tree <- stats::hclust(d.mat, method="single")
stats::cutree(cl.tree, k=3)
}, kmeans={
stats::kmeans(X, 3)
})
time.dt.list[[paste(N)]] <- data.table(N, timing.df)
}
time.dt <- do.call(rbind, time.dt.list)
time.dt[, data.size := N]
time.dt[, time.seconds := time/1e9]
time.dt[, algorithm := expr]
# g <- ggplot() + geom_line(aes(time.dt$,MC.dt$loglik)) + xlab("the number of mixcomponents") + ylab("the log likelihood")
ggplot()+geom_point(aes(x=data.size,y=time.seconds,color=algorithm),data=time.dt)
return(time.dt)
}
Myplot(df)
Myplot(df)
Myplot <- function(data.set){
time.dt.list <- list()
for (N in seq(10, 50, by =10)) {
X <- data.set[1:N,]
timing.df <- microbenchmark::microbenchmark(hclust={
d.mat <- stats::dist(X, method="manhattan")
as.matrix(d.mat)
cl.tree <- stats::hclust(d.mat, method="single")
stats::cutree(cl.tree, k=3)
}, kmeans={
stats::kmeans(X, 3)
})
time.dt.list[[paste(N)]] <- data.table(N, timing.df)
}
time.dt <- do.call(rbind, time.dt.list)
time.dt[, data.size := N]
time.dt[, time.seconds := time/1e9]
time.dt[, algorithm := expr]
# g <- ggplot() + geom_line(aes(time.dt$,MC.dt$loglik)) + xlab("the number of mixcomponents") + ylab("the log likelihood")
ggplot()+geom_point(aes(x=data.size,y=time.seconds,color=algorithm),data=time.dt)
return(time.dt)
}
Myplot(df)
Myplot <- function(data.set){
time.dt.list <- list()
for (N in seq(10, 50, by =10)) {
X <- data.set[1:N,]
timing.df <- microbenchmark::microbenchmark(hclust={
d.mat <- stats::dist(X, method="manhattan")
as.matrix(d.mat)
cl.tree <- stats::hclust(d.mat, method="single")
stats::cutree(cl.tree, k=3)
}, kmeans={
stats::kmeans(X, 3)
})
time.dt.list[[paste(N)]] <- data.table(N, timing.df)
}
time.dt <- do.call(rbind, time.dt.list)
time.dt[, data.size := N]
time.dt[, time.seconds := time/1e9]
time.dt[, algorithm := expr]
# g <- ggplot() + geom_line(aes(time.dt$,MC.dt$loglik)) + xlab("the number of mixcomponents") + ylab("the log likelihood")
g<-ggplot()+geom_point(aes(x=data.size,y=time.seconds,color=algorithm),data=time.dt)
return(g)
}
Myplot(df)
Myplot <- function(data.set){
time.dt.list <- list()
for (N in seq(10, 1000, by =100)) {
X <- data.set[1:N,]
timing.df <- microbenchmark::microbenchmark(hclust={
d.mat <- stats::dist(X, method="manhattan")
as.matrix(d.mat)
cl.tree <- stats::hclust(d.mat, method="single")
stats::cutree(cl.tree, k=3)
}, kmeans={
stats::kmeans(X, 3)
})
time.dt.list[[paste(N)]] <- data.table(N, timing.df)
}
time.dt <- do.call(rbind, time.dt.list)
time.dt[, data.size := N]
time.dt[, time.seconds := time/1e9]
time.dt[, algorithm := expr]
g<-ggplot()+geom_point(aes(x=data.size,y=time.seconds,color=algorithm),data=time.dt)
return(g)
}
Myplot(df)
Myplot <- function(data.set){
time.dt.list <- list()
for (N in seq(10, 2000, by =100)) {
X <- data.set[1:N,]
timing.df <- microbenchmark::microbenchmark(hclust={
d.mat <- stats::dist(X, method="manhattan")
as.matrix(d.mat)
cl.tree <- stats::hclust(d.mat, method="single")
stats::cutree(cl.tree, k=3)
}, kmeans={
stats::kmeans(X, 3)
})
time.dt.list[[paste(N)]] <- data.table(N, timing.df)
}
time.dt <- do.call(rbind, time.dt.list)
time.dt[, data.size := N]
time.dt[, time.seconds := time/1e9]
time.dt[, algorithm := expr]
g<-ggplot()+geom_point(aes(x=data.size,y=time.seconds,color=algorithm),data=time.dt)
return(g)
}
Myplot(df)
Myplot <- function(data.set){
time.dt.list <- list()
for (N in seq(10, 1000, by =100)) {
X <- data.set[1:N,]
timing.df <- microbenchmark::microbenchmark(hclust={
d.mat <- stats::dist(X, method="manhattan")
as.matrix(d.mat)
cl.tree <- stats::hclust(d.mat, method="single")
stats::cutree(cl.tree, k=3)
}, kmeans={
stats::kmeans(X, 3)
})
time.dt.list[[paste(N)]] <- data.table(N, timing.df)
}
time.dt <- do.call(rbind, time.dt.list)
time.dt[, data.size := N]
time.dt[, time.seconds := time/1e9]
time.dt[, algorithm := expr]
g<-ggplot()+geom_point(aes(x=data.size,y=time.seconds,color=algorithm),data=time.dt)
return(g)
}
Myplot(df)
Myplot <- function(data.set){
time.dt.list <- list()
for (N in seq(10, 1000, by =100)) {
X <- data.set[1:N,]
timing.df <- microbenchmark::microbenchmark(hclust={
d.mat <- stats::dist(X, method="manhattan")
as.matrix(d.mat)
cl.tree <- stats::hclust(d.mat, method="single")
stats::cutree(cl.tree, k=3)
}, kmeans={
stats::kmeans(X, 3)
})
time.dt.list[[paste(N)]] <- data.table(N, timing.df)
}
time.dt <- do.call(rbind, time.dt.list)
time.dt[, data.size := N]
time.dt[, time.seconds := time/1e9]
time.dt[, algorithm := expr]
g<-ggplot()+geom_point(aes(x=data.size,y=time.seconds,color=algorithm),data=time.dt) +  geom_smooth()
return(g)
}
Myplot(df)
HCLUST <- function(data.matrix, K)
{
if(!is.matrix(data.matrix)){
stop('the first argument should be a matrix')
}
if(!is.atomic(K)){
stop('the second argument should be an atomic vector')
}
data.matrix <- data.matrix[,1:K]
data.distance<- dist(data.matrix)
if(!is.matrix(data.distance)){
data.distance = as.matrix(data.distance)
}
Nrows = nrow(data.distance)
diag(data.distance)=Inf
# Tracks group index
group_index = -(1:Nrows)
# hclust matrix result output
output = matrix(0,nrow=Nrows-1, ncol=2)
# hclust height output
height_output = rep(0,Nrows-1)
for(j in seq(1,Nrows-1))
{
# Find the minimum distance over all points in that group
height_output[j] = min(data.distance)
# get exactly a 0 value.
i = which(data.distance - height_output[j] == 0, arr.ind=TRUE)
# get more than one, and  merge one pair.
i = i[1,,drop=FALSE]
p = group_index[i]
#to order each m[j,] pair as follows:
p = p[order(p)]
output[j,] = p
# Agglomerate this pair and all previous groups they belong to
# into the current jth group:
grp = c(i, which(group_index %in% group_index[i[1,group_index[i]>0]]))
group_index[grp] = j
# Concoct replacement distances that consolidate our pair using `method`:
r = apply(data.distance[i,],2,"min")
# Move on to the next minimum distance, excluding current one by modifying
# the distance matrix:
data.distance[min(i),] = data.distance[,min(i)] = r
data.distance[min(i),min(i)]        = Inf
data.distance[max(i),] = data.distance[,max(i)] = Inf
}
# Return something similar to the output from hclust.
structure(list(merge = output, height = height_output))
}
i=seq(1,50,3)
x=as.matrix(iris)
str(x)
h=hclust(dist(x[,1:4]))
h1=HCLUST(x,4)
#print(cbind(h$merge[1:148,],h1$merge[1:148,]))
print(h$merge[1:148,])
print(h1$merge[1:148,])
match(setdiff(h, h1), h1)
HCLUST <- function(data.matrix, K)
{
if(!is.matrix(data.matrix)){
stop('the first argument should be a matrix')
}
if(!is.atomic(K)){
stop('the second argument should be an atomic vector')
}
data.matrix <- data.matrix[,1:K]
data.distance<- dist(data.matrix)
if(!is.matrix(data.distance)){
data.distance = as.matrix(data.distance)
}
Nrows = nrow(data.distance)
diag(data.distance)=Inf
# Tracks group index
group_index = -(1:Nrows)
# hclust matrix result output
output = matrix(0,nrow=Nrows-1, ncol=2)
# hclust height output
height_output = rep(0,Nrows-1)
for(j in seq(1,Nrows-1))
{
# Find the minimum distance over all points in that group
height_output[j] = min(data.distance)
# get exactly a 0 value.
i = which(data.distance - height_output[j] == 0, arr.ind=TRUE)
# get more than one, and  merge one pair.
i = i[1,,drop=FALSE]
p = group_index[i]
#to order each m[j,] pair as follows:
p = p[order(p)]
output[j,] = p
# Agglomerate this pair and all previous groups they belong to
# into the current jth group:
grp = c(i, which(group_index %in% group_index[i[1,group_index[i]>0]]))
group_index[grp] = j
# Concoct replacement distances that consolidate our pair using `method`:
r = apply(data.distance[i,],2,"min")
# Move on to the next minimum distance, excluding current one by modifying
# the distance matrix:
data.distance[min(i),] = data.distance[,min(i)] = r
data.distance[min(i),min(i)]        = Inf
data.distance[max(i),] = data.distance[,max(i)] = Inf
}
# Return something similar to the output from hclust.
structure(list(merge = output, height = height_output))
}
i=seq(1,50,3)
x=as.matrix(iris)
str(x)
h=hclust(dist(x[,1:4]))
h1=HCLUST(x,4)
print(cbind(h$merge[1:148,],'||', h1$merge[1:148,]))
HCLUST <- function(data.matrix, K)
{
if(!is.matrix(data.matrix)){
stop('the first argument should be a matrix')
}
if(!is.atomic(K)){
stop('the second argument should be an atomic vector')
}
data.matrix <- data.matrix[,1:K]
data.distance<- dist(data.matrix)
if(!is.matrix(data.distance)){
data.distance = as.matrix(data.distance)
}
Nrows = nrow(data.distance)
diag(data.distance)=Inf
# Tracks group index
group_index = -(1:Nrows)
# hclust matrix result output
output = matrix(0,nrow=Nrows-1, ncol=2)
# hclust height output
height_output = rep(0,Nrows-1)
for(j in seq(1,Nrows-1))
{
# Find the minimum distance over all points in that group
height_output[j] = min(data.distance)
# get exactly a 0 value.
i = which(data.distance - height_output[j] == 0, arr.ind=TRUE)
# get more than one, and  merge one pair.
i = i[1,,drop=FALSE]
p = group_index[i]
#to order each m[j,] pair as follows:
p = p[order(p)]
output[j,] = p
# Agglomerate this pair and all previous groups they belong to
# into the current jth group:
grp = c(i, which(group_index %in% group_index[i[1,group_index[i]>0]]))
group_index[grp] = j
# Concoct replacement distances that consolidate our pair using `method`:
r = apply(data.distance[i,],2,"min")
# Move on to the next minimum distance, excluding current one by modifying
# the distance matrix:
data.distance[min(i),] = data.distance[,min(i)] = r
data.distance[min(i),min(i)]        = Inf
data.distance[max(i),] = data.distance[,max(i)] = Inf
}
# Return something similar to the output from hclust.
structure(list(merge = output, height = height_output))
}
i=seq(1,50,3)
x=as.matrix(iris)
str(x)
h=hclust(dist(x[,1:4]))
h1=HCLUST(x,4)
print(cbind(h$merge,'||', h1$merge))
ARI <-function(dt,df,cluster_sizes){
metrics.dt.list1 <- list()
metrics.dt.list2 <- list()
metrics.dt.list3 <- list()
for(n.clusters in 1: cluster_sizes){
dist.mat <- dist(df,method = "manhattan")
as.matrix(dist.mat)
cl.tree1 <- hclust(dist.mat, method="single")
gr.vector1<-cutree(cl.tree1, n.clusters)
first.result <- data.table(n.clusters,ARI1=pdfCluster::adj.rand.index(gr.vector1, dt[["V1"]]))
cl.tree2 <- hclust(dist.mat, method="average")
gr.vector2<-cutree(cl.tree2, n.clusters)
second.result <- data.table(n.clusters,ARI2=pdfCluster::adj.rand.index(gr.vector2, dt[["V1"]]))
fit1 <- kmeans(df,n.clusters)
third.result <- data.table(n.clusters,ARI3=pdfCluster::adj.rand.index(fit1$cluster, dt[["V1"]]))
metrics.dt.list1[[paste(n.clusters)]] <- first.result
metrics.dt.list2[[paste(n.clusters)]] <- second.result
metrics.dt.list3[[paste(n.clusters)]] <- third.result
}
metrics.dt1 <- do.call(rbind, metrics.dt.list1)
metrics.dt2 <- do.call(rbind, metrics.dt.list2)
metrics.dt3 <- do.call(rbind, metrics.dt.list3)
# g <- ggplot()+
#      geom_line(aes(n.clusters, ARI1 , color ='single'),data=metrics.dt1)+
#      geom_line(aes(n.clusters, ARI2, color ='average'),data=metrics.dt2)+
#      geom_line(aes(n.clusters, ARI3, color ='Kmeans'),data=metrics.dt3) +
#      xlab("the number of clusters") + ylab("ARI")+
#      scale_color_manual(values = c("red", "green", "blue"),
#                    labels = c("single",
#                               "average",
#                               "Kmeans"),
#                    name = 'Algorithm')
g<-ggplot()+
geom_line(aes(n.clusters, ARI1 , color ='single'),data=metrics.dt1)+
geom_line(aes(n.clusters, ARI2, color ='average'),data=metrics.dt2)+
geom_line(aes(n.clusters, ARI3, color ='Kmeans'),data=metrics.dt3) +
xlab("the number of clusters") + ylab("ARI")
return(g)
}
ARI(dt,df,10)
library(stats)
library(ggplot2)
library(data.table)
library(microbenchmark)
# use data.table::fread to read the compressed CSV data file into R as a data table.
dt<- fread("zip.test.gz")
#To exclude the label column (that is the first column)
df<-as.matrix(dt[, -1])
library(stats)
library(ggplot2)
library(data.table)
library(microbenchmark)
# use data.table::fread to read the compressed CSV data file into R as a data table.
dt<- fread("zip.test.gz")
#To exclude the label column (that is the first column)
df<-as.matrix(dt[, -1])
KMT <- function(data.set, g){
start_time <- Sys.time()
kclu<-kmeans(data.set, g)
end_time <- Sys.time()
total_time = end_time - start_time
return(total_time)
}
KMT(df,10)
HCT <- function(data.set, g){
iter <- seq(100,1000,100)
for (size in iter) {
start_time <- Sys.time()
dist.mat <- dist(data.set[1:size,],method = "manhattan")
as.matrix(dist.mat)
cl.tree<-hclust(dist.mat)
cutree(cl.tree, g)
end_time <- Sys.time()
total_time = end_time - start_time
print(paste0("When the size is ", size, " the total time cost are: ", total_time))
}
}
HCT(df,10)
Myplot <- function(data.set){
time.dt.list <- list()
for (N in seq(10, 1000, by =100)) {
X <- data.set[1:N,]
timing.df <- microbenchmark::microbenchmark(hclust={
d.mat <- stats::dist(X, method="manhattan")
as.matrix(d.mat)
cl.tree <- stats::hclust(d.mat, method="single")
stats::cutree(cl.tree, k=3)
}, kmeans={
stats::kmeans(X, 3)
})
time.dt.list[[paste(N)]] <- data.table(N, timing.df)
}
time.dt <- do.call(rbind, time.dt.list)
time.dt[, data.size := N]
time.dt[, time.seconds := time/1e9]
time.dt[, algorithm := expr]
g<-ggplot()+geom_point(aes(x=data.size,y=time.seconds,color=algorithm),data=time.dt)
return(g)
}
Myplot(df)
